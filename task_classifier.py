"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—Ä–∏—Å–≤–æ–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π JIRA –∑–∞–¥–∞—á–∞–º
"""
import pandas as pd
import os
import re
from datetime import datetime
from clients.ai_client import create_default_client


def load_tasks_and_categories(data_folder="classification_data"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ Excel —Ñ–∞–π–ª–æ–≤"""
    
    tasks_file = os.path.join(data_folder, "tasks.xlsx")
    categories_file = os.path.join(data_folder, "final_categories.xlsx")
    
    if not os.path.exists(tasks_file):
        raise FileNotFoundError(f"–§–∞–π–ª –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω: {tasks_file}")
    
    if not os.path.exists(categories_file):
        raise FileNotFoundError(f"–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {categories_file}")
    
    tasks_df = pd.read_excel(tasks_file)
    categories_df = pd.read_excel(categories_file)
    
    print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–¥–∞—á: {len(tasks_df)}")
    print(f"üè∑Ô∏è –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(categories_df)}")
    
    return tasks_df, categories_df


def classify_tasks_with_llm(tasks_batch, categories_df, batch_num, total_batches, llm_client):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –±–∞—Ç—á –∑–∞–¥–∞—á —Å –ø–æ–º–æ—â—å—é LLM"""
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    categories_text = ""
    for idx, row in categories_df.iterrows():
        categories_text += f"{idx+1}. {row['–ù–∞–∑–≤–∞–Ω–∏–µ']}: {row['–û–ø–∏—Å–∞–Ω–∏–µ']}\n"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    tasks_text = ""
    for idx, (_, row) in enumerate(tasks_batch.iterrows()):
        tasks_text += f"{idx+1}. [{row['key']}] {row['title']}\n"
        if row['description']:
            # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
            desc = row['description']
            tasks_text += f"   –û–ø–∏—Å–∞–Ω–∏–µ: {desc}\n"
        tasks_text += f"   –¢–∏–ø: {row['issuetype']}\n\n"
    
    prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ IT-–∑–∞–¥–∞—á. –û–ø—Ä–µ–¥–µ–ª–∏ –∫ –∫–∞–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫–∞–∂–¥–∞—è –∑–∞–¥–∞—á–∞.

–î–û–°–¢–£–ü–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò:
{categories_text}

–ó–ê–î–ê–ß–ò –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò (–±–∞—Ç—á {batch_num}/{total_batches}):
{tasks_text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ –≤—ã–±–µ—Ä–∏ –û–î–ù–£ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
2. –ò—Å–ø–æ–ª—å–∑—É–π –Ω–æ–º–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (1, 2, 3, ...)
3. –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –Ω–∏ –∫ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –≤—ã–±–µ—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ –±–ª–∏–∑–∫—É—é

–í–ï–†–ù–ò –†–ï–ó–£–õ–¨–¢–ê–¢ –í –§–û–†–ú–ê–¢–ï:
1;3
2;1
3;7
...

–ì–î–ï:
- –ü–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ = –Ω–æ–º–µ—Ä –∑–∞–¥–∞—á–∏ –≤ –±–∞—Ç—á–µ
- –í—Ç–æ—Ä–æ–µ —á–∏—Å–ª–æ = –Ω–æ–º–µ—Ä –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

–í–ê–ñ–ù–û:
- –¢–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –∏ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π
- –ö–∞–∂–¥–∞—è –∑–∞–¥–∞—á–∞ –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
- {len(tasks_batch)} —Å—Ç—Ä–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ"""

    print(f"ü§ñ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é –±–∞—Ç—á {batch_num}/{total_batches} ({len(tasks_batch)} –∑–∞–¥–∞—á)...")
    response = llm_client.simple_chat(prompt)
    return response


def parse_classification_response(response_text, tasks_batch, categories_df):
    """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    
    results = []
    lines = response_text.strip().split('\n')
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    category_names = categories_df['–ù–∞–∑–≤–∞–Ω–∏–µ'].tolist()
    
    for line in lines:
        line = line.strip()
        if not line or ';' not in line:
            continue
            
        try:
            parts = line.split(';')
            if len(parts) >= 2:
                task_idx = int(parts[0]) - 1  # –ò–Ω–¥–µ–∫—Å –∑–∞–¥–∞—á–∏ (–Ω–∞—á–∏–Ω–∞–µ–º —Å 0)
                category_idx = int(parts[1]) - 1  # –ò–Ω–¥–µ–∫—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞—á–∏–Ω–∞–µ–º —Å 0)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–æ–≤
                if 0 <= task_idx < len(tasks_batch) and 0 <= category_idx < len(categories_df):
                    task_row = tasks_batch.iloc[task_idx]
                    category_name = category_names[category_idx]
                    
                    results.append({
                        'key': task_row['key'],
                        'category': category_name,
                        'category_id': category_idx + 1
                    })
                    
        except (ValueError, IndexError) as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ '{line}': {e}")
            continue
    
    return results


def classify_all_tasks(tasks_df, categories_df, batch_size=20, data_folder="classification_data"):
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    
    Args:
        tasks_df (pd.DataFrame): DataFrame —Å –∑–∞–¥–∞—á–∞–º–∏
        categories_df (pd.DataFrame): DataFrame —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
        batch_size (int): —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è LLM (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 20)
        data_folder (str): –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    
    Returns:
        pd.DataFrame: DataFrame —Å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
        str: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    print(f"\nüéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è {len(tasks_df)} –∑–∞–¥–∞—á –ø–æ {len(categories_df)} –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º...")
    
    # –°–æ–∑–¥–∞–µ–º LLM –∫–ª–∏–µ–Ω—Ç
    llm_client = create_default_client()
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π DataFrame
    classified_df = tasks_df.copy()
    classified_df['assigned_category'] = ''
    classified_df['category_id'] = 0
    classified_df['classification_confidence'] = 'llm'
    
    all_classifications = []
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏
    total_batches = (len(tasks_df) + batch_size - 1) // batch_size
    print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
    print(f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π: {total_batches}")
    
    for i in range(0, len(tasks_df), batch_size):
        batch_num = (i // batch_size) + 1
        tasks_batch = tasks_df.iloc[i:i+batch_size]
        
        try:
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –±–∞—Ç—á
            response = classify_tasks_with_llm(
                tasks_batch, categories_df, batch_num, total_batches, llm_client
            )
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            batch_results = parse_classification_response(response, tasks_batch, categories_df)
            
            print(f"‚úÖ –ë–∞—Ç—á {batch_num}: –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {len(batch_results)}/{len(tasks_batch)} –∑–∞–¥–∞—á")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            all_classifications.extend(batch_results)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}: {e}")
            continue
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫ DataFrame
    for result in all_classifications:
        mask = classified_df['key'] == result['key']
        classified_df.loc[mask, 'assigned_category'] = result['category']
        classified_df.loc[mask, 'category_id'] = result['category_id']
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    classified_count = (classified_df['assigned_category'] != '').sum()
    unclassified_count = len(classified_df) - classified_count
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
    print(f"   ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {classified_count}")
    print(f"   ‚ùå –ù–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {unclassified_count}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    if classified_count > 0:
        print(f"\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        category_counts = classified_df[classified_df['assigned_category'] != '']['assigned_category'].value_counts()
        for category, count in category_counts.items():
            print(f"   {category}: {count} –∑–∞–¥–∞—á")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    os.makedirs(data_folder, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = os.path.join(data_folder, f"classified_tasks_{timestamp}.xlsx")
    classified_df.to_excel(results_file, index=False, sheet_name='Classified_Tasks')
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    main_results_file = os.path.join(data_folder, "classified_tasks.xlsx")
    classified_df.to_excel(main_results_file, index=False, sheet_name='Classified_Tasks')
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"   üìÑ {results_file}")
    print(f"   üìÑ {main_results_file}")
    
    return classified_df, main_results_file


def main_classification():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–¥–∞—á"""
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        tasks_df, categories_df = load_tasks_and_categories()
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏
        classified_df, results_file = classify_all_tasks(tasks_df, categories_df)
        
        print("\nüéâ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
        return classified_df, results_file
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None, None


if __name__ == "__main__":
    main_classification()
